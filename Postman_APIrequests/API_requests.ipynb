{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b83aa17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "api_key=os.getenv(\"LLama_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cf6f4b8-0b26-4e90-a5a0-283937066d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"choices\":[{\"finish_reason\":\"stop\",\"index\":0,\"message\":{\"role\":\"assistant\",\"content\":\"Artificial Intelligence (AI) refers to the development of computer systems that can perform tasks that typically require human intelligence, such as learning, problem-solving, and decision-making.\\n\\nAI systems can be categorized into three main types:\\n\\n1. **Narrow or Weak AI**: This type of AI is designed to perform a specific task, such as image recognition, speech recognition, or playing chess. Narrow AI systems are trained on a specific dataset and can learn from that data to improve their performance.\\n2. **General or Strong AI**: This type of AI is designed to perform any intellectual task that a human can. General AI systems are expected to be able to reason, learn, and apply knowledge across a wide range of tasks, similar to how humans do.\\n3. **Superintelligence**: This type of AI is significantly more intelligent than current AI systems. Superintelligence is often considered to be a hypothetical AI system that could surpass human intelligence in many areas.\\n\\nAI systems use various techniques, such as machine learning, deep learning, and natural language processing, to enable them to learn from data and make decisions. These techniques allow AI systems to:\\n\\n* **Analyze large datasets**: AI systems can quickly process and analyze large amounts of data, making them ideal for tasks such as image recognition and natural language processing.\\n* **Make predictions**: AI systems can use machine learning algorithms to predict outcomes based on data, making them useful for tasks such as forecasting and decision-making.\\n* **Learn from feedback**: AI systems can learn from feedback and adjust their behavior accordingly, making them useful for tasks such as control systems and robotics.\\n\\nWhile AI has made significant progress in recent years, there are still many challenges to overcome, such as:\\n\\n* **Data quality**: AI systems require high-quality data to learn and improve, which can be a challenge in areas where data is limited or biased.\\n* **Explainability**: AI systems can be complex and difficult to understand, which can make it challenging to explain their decisions or actions.\\n* **Safety and ethics**: AI systems raise important questions about safety and ethics, such as how AI systems should be designed and deployed to prevent harm.\\n\\nOverall, AI has the potential to revolutionize many aspects of our lives, from healthcare and education to transportation and finance. However, it's essential to address the challenges and concerns surrounding AI to ensure that its benefits are realized while minimizing its risks.\"}}],\"created\":1754347860,\"model\":\"Llama-3.2-1B-Instruct.IQ4_XS\",\"system_fingerprint\":\"b1-f3471ce\",\"object\":\"chat.completion\",\"usage\":{\"completion_tokens\":479,\"prompt_tokens\":44,\"total_tokens\":523},\"id\":\"chatcmpl-BZD83OUMDIoFduGPTgzkKNHu2E6Q7oOz\",\"timings\":{\"prompt_n\":16,\"prompt_ms\":183.162,\"prompt_per_token_ms\":11.447625,\"prompt_per_second\":87.3543638964414,\"predicted_n\":479,\"predicted_ms\":20587.527,\"predicted_per_token_ms\":42.98022338204593,\"predicted_per_second\":23.266514720296424}}\n"
     ]
    }
   ],
   "source": [
    "url = \"http://127.0.0.1:1337/v1/chat/completions\"\n",
    "\n",
    "payload = json.dumps({\n",
    "  \"model\": \"Llama-3.2-1B-Instruct.IQ4_XS\",\n",
    "  \"messages\": [\n",
    "    {\n",
    "      \"content\": \"You are a helpful assistant.\",\n",
    "      \"role\": \"system\"\n",
    "    },\n",
    "    {\n",
    "      \"content\": \"What is ai\",\n",
    "      \"role\": \"user\"\n",
    "    }\n",
    "  ]\n",
    "})\n",
    "headers = {\n",
    "  'Authorization': f'Bearer {api_key}',\n",
    "  'Content-Type': 'application/json'\n",
    "}\n",
    "\n",
    "response = requests.request(\"POST\", url, headers=headers, data=payload)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13db4857",
   "metadata": {},
   "source": [
    "# LLM Toolbox: Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40cd5d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"choices\":[{\"finish_reason\":\"stop\",\"index\":0,\"message\":{\"content\":\"I am writing to inform you that I have decided to resign from my position as a [insert position] at [insert company name]. After much thought and consideration, I have come to the conclusion that it is in the best interest of both myself and the company to move on.\\n\\nI have thoroughly enjoyed my time at [insert company name], and I am grateful for the opportunity to have worked with such a talented and dedicated team. However, I feel that it is time for me to pursue new opportunities and explore new challenges.\\n\\nI would like to thank you for your support and guidance during my time at [insert company name]. I have learned so much from you and I am grateful for the lessons and experiences that I have gained.\\n\\nI wish you all the best in your future endeavors, and I hope that you will continue to be successful in your work.\\n\\nSincerely,\\n\\n[Your Name]\",\"role\":\"assistant\"}}],\"created\":1754012336,\"id\":\"chatcmpl-ozerGScm62StkqQ8vMZSoyc91l5tZuL3\",\"model\":\"tinyllama:1b\",\"object\":\"chat.completion\",\"system_fingerprint\":\"b1-f3471ce\",\"timings\":{\"predicted_ms\":6503.0079999999998,\"predicted_n\":198,\"predicted_per_second\":30.447448319300854,\"predicted_per_token_ms\":32.843474747474744,\"prompt_ms\":219.52000000000001,\"prompt_n\":38,\"prompt_per_second\":173.10495626822157,\"prompt_per_token_ms\":5.7768421052631584},\"usage\":{\"completion_tokens\":198,\"prompt_tokens\":48,\"total_tokens\":246}}\n"
     ]
    }
   ],
   "source": [
    "payload = json.dumps({\n",
    "  \"model\": \"Llama-3.2-1B-Instruct.IQ4_XS\",\n",
    "  \"messages\": [\n",
    "    {\n",
    "      \"content\": \"You are a witty and sarcastic assistant\",\n",
    "      \"role\": \"system\"\n",
    "    },\n",
    "    {\n",
    "      \"content\": \"Write a resignation letter in 1-2 lines\",\n",
    "      \"role\": \"user\"\n",
    "    }\n",
    "  ],\n",
    "    \"temperature\":0.1 #With increased temperature it becomes more creative\n",
    "})\n",
    "headers = {\n",
    "  'Authorization': f'Bearer {api_key}',\n",
    "  'Content-Type': 'application/json'\n",
    "}\n",
    "\n",
    "response = requests.request(\"POST\", url, headers=headers, data=payload)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d2816f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"choices\":[{\"finish_reason\":\"stop\",\"index\":0,\"message\":{\"content\":\"Dear HR,\\n\\nAs of [date of resignation], I have come to the conclusion that my job at [company] is no longer fulfilling me in the way I deserve it to be. Therefore, I kindly ask to be released from my employment agreement with [company] on [date of resignation].\\n\\nI have made this decision after careful consideration, considering the many opportunities that await me in [insert a statement that expresses your willingness to pursue a different career path], as well as my personal commitments and obligations.\\n\\nI am leaving [company] with a sincere gratitude for the opportunities, colleagues, and environment provided to me during my time here, and wish all of the best for your continued success.\\n\\nBest regards,\\n\\n[Your Name]\\n\\n[Your Position and Title]\",\"role\":\"assistant\"}}],\"created\":1754012342,\"id\":\"chatcmpl-OucwunpjX4N1N1xl7fAWb7amF6R0zR52\",\"model\":\"tinyllama:1b\",\"object\":\"chat.completion\",\"system_fingerprint\":\"b1-f3471ce\",\"timings\":{\"predicted_ms\":5803.4859999999999,\"predicted_n\":182,\"predicted_per_second\":31.360461625995136,\"predicted_per_token_ms\":31.887285714285714,\"prompt_ms\":33.177,\"prompt_n\":1,\"prompt_per_second\":30.141362992434519,\"prompt_per_token_ms\":33.177},\"usage\":{\"completion_tokens\":182,\"prompt_tokens\":48,\"total_tokens\":230}}\n"
     ]
    }
   ],
   "source": [
    "payload = json.dumps({\n",
    "  \"model\": \"Llama-3.2-1B-Instruct.IQ4_XS\",\n",
    "  \"messages\": [\n",
    "    {\n",
    "      \"content\": \"You are a witty and sarcastic assistant\",\n",
    "      \"role\": \"system\"\n",
    "    },\n",
    "    {\n",
    "      \"content\": \"Write a resignation letter in 1-2 lines\",\n",
    "      \"role\": \"user\"\n",
    "    }\n",
    "  ],\n",
    "    \"temperature\":1.7 #With increased temperature it becomes more creative, ~1 is optimal value\n",
    "})\n",
    "headers = {\n",
    "  'Authorization': f'Bearer {api_key}',\n",
    "  'Content-Type': 'application/json'\n",
    "}\n",
    "\n",
    "response = requests.request(\"POST\", url, headers=headers, data=payload)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1311f350",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "277b6369",
   "metadata": {},
   "source": [
    "# LLM Toolbox: Max Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2107579-9328-4840-ac3a-77954bc4a796",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c81bd430",
   "metadata": {},
   "source": [
    "## Character Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c03ad2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def character_tockenization(text: str)->list:\n",
    "    tockens=list(text)\n",
    "    return tockens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19e8d8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"Our manager is like brocken clock, he is right twice a day\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac6b3486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O',\n",
       " 'u',\n",
       " 'r',\n",
       " ' ',\n",
       " 'm',\n",
       " 'a',\n",
       " 'n',\n",
       " 'a',\n",
       " 'g',\n",
       " 'e',\n",
       " 'r',\n",
       " ' ',\n",
       " 'i',\n",
       " 's',\n",
       " ' ',\n",
       " 'l',\n",
       " 'i',\n",
       " 'k',\n",
       " 'e',\n",
       " ' ',\n",
       " 'b',\n",
       " 'r',\n",
       " 'o',\n",
       " 'c',\n",
       " 'k',\n",
       " 'e',\n",
       " 'n',\n",
       " ' ',\n",
       " 'c',\n",
       " 'l',\n",
       " 'o',\n",
       " 'c',\n",
       " 'k',\n",
       " ',',\n",
       " ' ',\n",
       " 'h',\n",
       " 'e',\n",
       " ' ',\n",
       " 'i',\n",
       " 's',\n",
       " ' ',\n",
       " 'r',\n",
       " 'i',\n",
       " 'g',\n",
       " 'h',\n",
       " 't',\n",
       " ' ',\n",
       " 't',\n",
       " 'w',\n",
       " 'i',\n",
       " 'c',\n",
       " 'e',\n",
       " ' ',\n",
       " 'a',\n",
       " ' ',\n",
       " 'd',\n",
       " 'a',\n",
       " 'y']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "character_tockenization(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c9b9e1",
   "metadata": {},
   "source": [
    "## Word Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee51f646",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"Dear Sir, I won't be able to attend office, because I threw the laptop in the snoflake lake\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24cfa6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "token=text.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66c0605c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dear',\n",
       " 'Sir,',\n",
       " 'I',\n",
       " \"won't\",\n",
       " 'be',\n",
       " 'able',\n",
       " 'to',\n",
       " 'attend',\n",
       " 'office,',\n",
       " 'because',\n",
       " 'I',\n",
       " 'threw',\n",
       " 'the',\n",
       " 'laptop',\n",
       " 'in',\n",
       " 'the',\n",
       " 'snoflake',\n",
       " 'lake']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6aa1b0a-155d-4ce8-b9e2-1578e9b1c93f",
   "metadata": {},
   "source": [
    "## Sub-word Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "061e4c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb6e72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer for BERT (can use RoBERTa, GPT2, etc.)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f31620",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Tokenization is interesting because it handles unseen words cleverly.\"\n",
    "\n",
    "# Basic tokenization\n",
    "tokens = tokenizer.tokenize(text)\n",
    "\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c62159f",
   "metadata": {},
   "source": [
    "## Tokens to IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d595341e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer for BERT (can use RoBERTa, GPT2, etc.)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162c3508",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Happy Bday to me\"\n",
    "\n",
    "# Basic tokenization\n",
    "tokens = tokenizer.tokenize(text)\n",
    "\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61e56e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tocken_to_number=tokenizer.convert_tokens_to_ids(tokens)\n",
    "print(tocken_to_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f792d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "40516689",
   "metadata": {},
   "source": [
    "## Word vectorizations and embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6b3a7e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "088e8786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tocken for the word dog is 3899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.4935e-02,  1.2444e-02,  9.1277e-03, -1.4333e-02, -2.4053e-02,\n",
      "         -8.8391e-03, -5.0729e-03,  3.4792e-02,  4.9943e-02, -9.7622e-03,\n",
      "         -6.7302e-02, -5.5808e-02, -8.4477e-02,  1.1301e-02, -4.0511e-02,\n",
      "         -9.3478e-02,  2.2908e-02, -3.2941e-02,  1.7266e-03,  1.7777e-02,\n",
      "         -6.2316e-03, -4.9649e-02, -4.4828e-02, -3.0987e-02,  1.2962e-02,\n",
      "         -8.1616e-03,  3.4435e-03, -6.5256e-03, -1.5115e-02, -1.0003e-01,\n",
      "          1.1840e-02, -7.8496e-03, -8.9664e-02,  1.3541e-03, -2.7378e-03,\n",
      "          2.0956e-02, -4.5374e-02, -2.3927e-02, -5.5758e-02, -1.1604e-02,\n",
      "          9.9464e-03,  2.5420e-02, -2.0281e-02, -1.8136e-02,  1.3837e-02,\n",
      "         -1.0506e-02, -3.3592e-03, -2.0255e-02,  7.4511e-02, -6.6017e-02,\n",
      "          2.9210e-02,  2.0391e-02, -2.9849e-02, -2.0139e-02, -1.2126e-02,\n",
      "         -3.3120e-02,  4.5548e-02, -1.3883e-02, -4.8897e-02, -5.5070e-02,\n",
      "         -1.6012e-02,  1.5712e-02, -2.4265e-03,  5.7435e-03, -5.1066e-02,\n",
      "          2.9750e-02, -4.9678e-02, -1.5611e-02, -5.0391e-02, -8.7561e-03,\n",
      "          4.9816e-02,  5.5756e-02,  9.9560e-03, -2.2161e-03, -5.0583e-02,\n",
      "         -7.5697e-03,  2.2142e-02,  8.3733e-03, -2.8285e-02, -5.8035e-03,\n",
      "          4.6313e-02, -7.4295e-02, -6.2570e-02, -5.9992e-02, -6.4988e-02,\n",
      "          6.4516e-03, -1.3329e-02, -6.1383e-02, -8.5418e-04,  4.9580e-02,\n",
      "         -6.1290e-02, -3.3759e-02, -2.8210e-02,  2.7397e-02, -1.6484e-02,\n",
      "         -3.2568e-02, -1.8441e-02, -4.0004e-02, -2.6520e-02, -3.6178e-02,\n",
      "         -1.8212e-02, -8.7887e-03,  3.2123e-02,  4.5408e-03, -6.3709e-03,\n",
      "         -5.0798e-02, -4.5205e-02, -7.4762e-02,  1.2139e-03,  2.5720e-02,\n",
      "          7.9669e-03,  3.0161e-03, -3.4022e-02, -9.5219e-03, -2.7898e-02,\n",
      "          2.5679e-02, -5.6830e-02, -3.5690e-02, -2.3468e-02,  1.7077e-02,\n",
      "         -9.5808e-03,  4.0266e-04,  7.4773e-03, -3.3870e-02, -1.9058e-02,\n",
      "         -3.6857e-02, -7.5846e-02, -7.0775e-02, -7.6856e-02, -8.8733e-03,\n",
      "         -3.1069e-02, -2.9176e-03, -7.0607e-02, -1.9362e-02,  6.7830e-03,\n",
      "         -3.0983e-03,  3.8976e-02,  1.1001e-02, -1.3850e-02, -3.5830e-02,\n",
      "         -2.6310e-02, -7.2046e-02,  2.6586e-02, -2.6182e-03, -5.6749e-02,\n",
      "         -1.3217e-02, -5.3053e-02, -6.6048e-03, -6.1760e-02, -6.9015e-02,\n",
      "         -1.0332e-02, -1.0387e-01, -4.9677e-02, -7.4176e-02, -8.5430e-03,\n",
      "         -1.6353e-02,  2.6076e-02, -3.1495e-02,  3.0475e-02, -5.3020e-03,\n",
      "         -4.1500e-03, -8.6029e-03, -2.8387e-02, -9.5474e-03, -2.3640e-02,\n",
      "         -2.7691e-02, -3.6506e-02, -4.7839e-02, -8.7098e-03, -2.3586e-03,\n",
      "          1.0471e-02, -4.4278e-02,  1.2709e-02,  4.3073e-02, -2.1199e-02,\n",
      "         -5.9193e-02,  1.1267e-02, -2.2370e-02, -1.5484e-02,  2.1221e-02,\n",
      "         -2.7412e-03,  2.1437e-02, -4.4558e-02,  8.6088e-04,  2.3496e-02,\n",
      "         -5.7534e-02, -1.6890e-02, -2.8702e-02,  2.7675e-02, -7.1197e-02,\n",
      "         -8.3799e-02, -2.7158e-02, -1.7777e-02, -2.5723e-02,  1.5970e-02,\n",
      "         -2.9671e-02,  8.9409e-03, -7.2594e-03,  6.9052e-04, -1.2988e-02,\n",
      "         -1.3124e-02, -3.4577e-02, -5.2808e-02, -1.4693e-02, -8.6623e-03,\n",
      "         -2.4755e-02, -8.2493e-03, -5.7107e-03,  4.0699e-03, -2.0717e-02,\n",
      "         -2.9740e-02, -1.5063e-02,  2.4674e-02,  6.7634e-02, -1.7800e-02,\n",
      "          1.7103e-02, -8.3632e-02,  3.3903e-02,  1.6969e-02, -2.5418e-03,\n",
      "         -7.3242e-02, -5.7605e-03, -1.7639e-02,  4.4034e-02, -4.7397e-02,\n",
      "         -1.1264e-02,  5.5247e-03, -3.8757e-02,  2.2800e-02, -9.2876e-03,\n",
      "         -2.8282e-02, -9.2056e-02, -8.4035e-02,  2.2718e-02, -7.1667e-02,\n",
      "          1.2158e-02, -4.5337e-03,  4.7784e-02,  1.3561e-02, -3.9558e-02,\n",
      "         -1.0921e-02, -3.3451e-02, -5.9671e-02, -5.5777e-02, -6.2552e-02,\n",
      "         -1.9763e-02, -3.6026e-02, -9.0654e-03, -7.1578e-03, -5.9177e-02,\n",
      "         -3.6230e-03, -1.2048e-01,  3.3310e-02, -3.1953e-03, -3.3910e-02,\n",
      "         -3.1023e-02,  2.7600e-02, -3.7302e-02,  5.0895e-03, -5.6059e-02,\n",
      "          4.5940e-04, -1.0170e-01, -4.8222e-02, -7.3053e-02,  1.4640e-02,\n",
      "         -6.4384e-03, -2.3574e-02, -1.3520e-02, -1.4493e-02, -5.4003e-02,\n",
      "          1.0100e-02,  1.2323e-02,  1.0840e-03, -3.3067e-02, -6.5742e-04,\n",
      "         -5.4734e-03, -3.6939e-03, -1.8071e-02, -5.6621e-02,  1.9943e-02,\n",
      "         -1.6308e-02, -2.9473e-03, -2.4461e-03, -7.8846e-02, -4.3163e-02,\n",
      "         -6.5202e-02, -4.5317e-02, -2.3282e-02, -2.8626e-02, -3.2525e-03,\n",
      "         -5.8646e-02, -4.1152e-02, -6.6420e-02, -2.3511e-02, -3.4347e-02,\n",
      "          2.1442e-02, -7.6491e-02, -5.6547e-02, -3.3335e-02,  9.0249e-03,\n",
      "          2.8479e-02, -1.7205e-02,  7.2498e-02, -6.9055e-03, -3.0498e-02,\n",
      "         -4.7837e-02, -1.7563e-02, -1.5357e-02,  3.0220e-02, -4.4421e-02,\n",
      "         -4.7643e-02, -4.7254e-02, -5.9757e-02, -2.1484e-02,  6.6938e-03,\n",
      "          4.6448e-05, -2.0075e-02, -8.3963e-03, -7.5050e-04, -3.2271e-02,\n",
      "          5.6801e-02,  3.8488e-02, -3.3234e-02, -2.7078e-02, -6.0087e-02,\n",
      "         -1.1286e-02, -2.4019e-02,  2.9383e-02, -5.1892e-03,  2.7386e-02,\n",
      "         -6.7571e-02, -6.3370e-02, -2.8892e-02,  2.7794e-02, -7.0000e-02,\n",
      "         -1.2083e-02, -6.1142e-02, -9.8442e-02,  4.1813e-02, -5.9992e-02,\n",
      "          2.8865e-02, -3.8707e-02, -3.5881e-02, -3.7418e-02,  6.4824e-03,\n",
      "         -5.4610e-03, -4.0851e-02, -1.3011e-02, -3.0475e-02,  6.3044e-02,\n",
      "          1.5497e-02,  1.6277e-02, -4.9830e-02,  4.1357e-02, -8.9698e-03,\n",
      "          2.5608e-02, -1.7566e-02, -1.1236e-02, -4.4380e-02,  3.9220e-02,\n",
      "         -4.5617e-02, -5.1199e-02,  3.2555e-03, -4.0406e-02,  4.0126e-02,\n",
      "         -8.1351e-02, -3.0360e-02,  1.1239e-02, -6.1479e-02, -1.8766e-02,\n",
      "          4.1225e-02, -7.7830e-02, -7.2969e-04, -2.6445e-02, -5.8524e-02,\n",
      "         -4.4569e-02, -7.1474e-02, -1.6545e-02, -2.6927e-02,  4.2390e-02,\n",
      "         -6.6815e-02, -6.4513e-02, -1.2289e-02, -1.7745e-02, -5.9152e-03,\n",
      "          2.5880e-02, -1.5484e-02,  2.7642e-02, -2.4343e-02,  3.6766e-02,\n",
      "         -5.4902e-02, -4.6740e-02, -8.5773e-02, -5.8115e-02, -5.0248e-02,\n",
      "         -9.4552e-03, -2.7795e-02, -5.8581e-02, -1.2965e-02,  2.4222e-02,\n",
      "         -2.9084e-02, -5.1697e-02, -2.8023e-02,  1.1345e-04, -9.9090e-03,\n",
      "         -2.4065e-02, -1.0976e-03, -1.0506e-02,  5.8837e-03,  1.1094e-02,\n",
      "          3.3330e-03, -2.7487e-02, -2.8955e-02, -2.6840e-02, -1.9532e-02,\n",
      "          5.3208e-02,  2.1958e-02, -1.5277e-02,  1.3780e-02, -2.6709e-02,\n",
      "         -2.0958e-02,  1.2196e-02, -6.6901e-02,  1.4965e-02,  1.2285e-02,\n",
      "          3.5532e-02, -8.1592e-02,  4.1491e-03, -8.3734e-02, -6.0422e-02,\n",
      "         -5.0337e-02, -2.7377e-02,  6.0660e-04, -2.1971e-02, -3.9472e-03,\n",
      "          6.5534e-03, -4.1016e-02, -5.5801e-03, -3.3487e-02, -6.6002e-02,\n",
      "          4.1078e-03,  3.8863e-02, -2.7069e-02, -1.7870e-03, -2.0085e-02,\n",
      "         -8.2453e-02,  3.0205e-02, -1.0170e-01, -5.3519e-02, -5.2982e-02,\n",
      "         -2.4317e-02,  1.0019e-02, -1.7570e-02, -8.2450e-02, -5.9336e-02,\n",
      "         -5.6918e-02, -2.4178e-02, -2.1890e-02, -2.7463e-02, -8.8307e-02,\n",
      "          1.2785e-02,  8.1914e-02, -3.3354e-03, -1.0855e-02, -2.3208e-02,\n",
      "         -1.4014e-02, -3.3651e-02, -6.2653e-02, -4.0431e-02, -3.4235e-03,\n",
      "          7.3214e-03, -5.8256e-02, -2.0836e-02,  4.4403e-03, -7.7434e-05,\n",
      "          3.2466e-03,  1.3832e-02,  7.9899e-03, -3.4155e-03, -8.6740e-02,\n",
      "         -2.7965e-02, -2.1563e-02,  5.4855e-03,  8.2891e-04, -7.1025e-02,\n",
      "         -1.4090e-02,  4.5072e-02,  3.8654e-02, -2.4525e-02, -3.1191e-02,\n",
      "         -3.6164e-02,  7.5544e-03, -3.1445e-03,  6.0522e-02, -1.3601e-02,\n",
      "         -4.3936e-03, -2.6236e-02,  2.7873e-02, -3.1118e-02, -1.4077e-02,\n",
      "         -1.1682e-02,  1.7445e-03, -2.7009e-02, -9.5569e-02,  1.3698e-02,\n",
      "          2.8302e-03,  1.1151e-02,  5.6224e-03, -3.6980e-02,  8.6310e-03,\n",
      "          2.7143e-03, -3.7354e-02, -4.2554e-02, -3.0015e-02, -4.5063e-02,\n",
      "          3.0180e-02,  6.4543e-04, -4.8108e-02, -7.8834e-02,  3.1213e-03,\n",
      "         -4.4406e-02, -3.7512e-02, -7.4020e-02, -1.6530e-02, -3.7251e-02,\n",
      "         -2.3720e-02,  1.8877e-03,  5.4353e-03, -7.3053e-03, -1.4989e-02,\n",
      "         -5.3530e-02, -4.7749e-02, -2.2033e-02, -7.5749e-03, -5.8701e-02,\n",
      "         -4.9468e-03,  2.2937e-03, -4.2616e-03, -5.7616e-02, -4.5368e-02,\n",
      "          5.1582e-03,  3.5463e-03, -4.0009e-03, -2.5891e-02,  8.3646e-03,\n",
      "         -2.1262e-02, -1.0062e-01, -4.9168e-02, -1.7826e-02,  7.9050e-03,\n",
      "          3.3201e-02,  2.2013e-02,  1.4118e-03, -2.5427e-02, -8.6857e-02,\n",
      "         -4.4282e-02, -2.3944e-03, -1.3822e-02, -1.5610e-02, -9.0647e-03,\n",
      "         -6.3860e-02, -4.3565e-02,  4.7798e-02,  3.9115e-02,  2.2675e-02,\n",
      "         -8.3356e-02, -5.2822e-02,  4.1665e-03, -1.9854e-02, -2.8954e-02,\n",
      "         -9.3344e-04, -1.8663e-02, -8.3206e-02,  2.4644e-02, -4.6643e-02,\n",
      "         -4.5372e-03, -3.6591e-02, -6.6811e-02,  2.3848e-02,  6.0836e-02,\n",
      "         -1.4929e-02,  5.4171e-03, -4.9774e-02, -2.0214e-03, -6.7846e-03,\n",
      "         -3.8327e-02,  6.5072e-02, -9.7981e-03, -4.4978e-02, -8.7484e-02,\n",
      "         -4.3833e-02, -2.6536e-02,  4.1346e-03, -6.6836e-02, -5.6286e-03,\n",
      "         -2.0644e-02,  5.1189e-03,  3.4320e-02, -1.7676e-02,  1.2807e-02,\n",
      "         -5.9985e-03, -1.1172e-02,  9.9250e-05, -1.2927e-03, -3.9051e-02,\n",
      "         -2.5900e-02, -6.3987e-02,  1.2923e-02, -9.4488e-02, -6.8468e-02,\n",
      "         -7.3965e-02, -3.1809e-04, -5.9041e-02, -6.0238e-04, -1.3063e-02,\n",
      "          2.0699e-02,  1.0690e-02, -4.7602e-02, -1.0581e-03, -2.2346e-02,\n",
      "          2.2978e-02, -2.3422e-02, -6.2740e-02, -1.6794e-02,  1.8564e-02,\n",
      "         -3.1269e-02, -5.6046e-03,  3.4425e-02, -1.4990e-02,  6.5353e-03,\n",
      "         -1.9959e-02,  1.1839e-02, -4.2629e-02, -2.9217e-02,  5.8823e-03,\n",
      "         -5.6423e-03, -1.7329e-02, -6.6831e-02, -4.4782e-02, -4.8743e-02,\n",
      "          1.3075e-02,  1.8111e-02, -4.9726e-02,  4.4699e-02, -3.3809e-02,\n",
      "         -3.6014e-02, -3.4400e-02, -2.9622e-02,  1.7093e-03,  1.6393e-02,\n",
      "         -5.9501e-02, -6.9537e-02, -2.7356e-02, -6.4026e-02, -3.5100e-02,\n",
      "         -2.8655e-02,  5.2704e-02,  7.7841e-02, -5.1659e-02, -3.7272e-02,\n",
      "         -2.7576e-02, -3.3306e-02, -5.0056e-02, -3.7573e-02, -8.0469e-03,\n",
      "         -6.5515e-02, -1.4451e-02, -5.3023e-02, -1.3336e-03, -2.2632e-02,\n",
      "          7.1129e-03, -8.7441e-02, -2.0082e-02, -2.4206e-02,  3.1337e-02,\n",
      "          1.8446e-02,  3.1316e-02, -1.4191e-02, -1.8054e-02,  5.3463e-02,\n",
      "          3.2752e-02,  2.3891e-02, -7.0613e-03, -8.0983e-03, -2.0372e-02,\n",
      "         -9.2922e-02,  2.4159e-02,  3.9190e-03, -7.3938e-02,  2.7766e-03,\n",
      "         -2.3717e-02, -1.7712e-02, -4.2614e-02,  3.7677e-02, -5.3803e-02,\n",
      "          2.8485e-02, -3.5806e-02,  2.9059e-02,  1.4289e-02, -4.3695e-02,\n",
      "          1.5343e-02, -4.1647e-02,  8.7248e-03, -1.0801e-01,  1.8978e-02,\n",
      "         -3.4344e-02,  1.8139e-02, -4.0768e-02, -2.2597e-03, -7.0892e-02,\n",
      "          2.1979e-03, -6.6231e-02, -4.8986e-03, -4.5573e-02, -1.0427e-02,\n",
      "          2.2685e-03,  1.8944e-02,  5.3736e-02,  1.9176e-02, -1.1415e-02,\n",
      "         -2.5194e-02, -2.1901e-02, -2.3767e-03,  1.7086e-02, -3.3183e-02,\n",
      "         -4.6560e-02,  1.0873e-02, -2.1847e-02, -2.3217e-02, -4.6579e-02,\n",
      "         -3.7423e-02, -1.9702e-02, -8.4762e-03, -4.6828e-02, -1.6231e-02,\n",
      "          3.7566e-02, -1.6913e-02, -3.2743e-02,  1.7344e-02, -1.8693e-03,\n",
      "         -3.2190e-02, -3.3506e-02,  3.9702e-02,  4.4353e-04, -1.7738e-02,\n",
      "         -2.0220e-02, -6.1430e-02,  1.0824e-02, -3.5435e-02, -1.2617e-02,\n",
      "          7.5960e-03,  5.8790e-03,  9.4042e-03, -2.3793e-03, -6.9173e-02,\n",
      "          7.3777e-03, -4.5595e-02,  2.4637e-02, -3.8106e-02, -1.7719e-02,\n",
      "         -5.5826e-02,  6.4352e-02, -4.1351e-02, -7.2365e-03, -1.1576e-01,\n",
      "         -4.4499e-02, -1.9311e-02,  2.3352e-02]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "token_dog=tokenizer.convert_tokens_to_ids([\"dog\"])[0]\n",
    "print(\"tocken for the word dog is\",token_dog)\n",
    "\n",
    "model=BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "word_vector_dog=model.embeddings.word_embeddings(torch.tensor([token_dog]))\n",
    "print(word_vector_dog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5cf65c95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vector_dog.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5d78cee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This means 768 features has been used to differenciate between different vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eef2a52",
   "metadata": {},
   "source": [
    "## Cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e5d55b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tocken_dog_id=tokenizer.convert_tokens_to_ids([\"dog\"])[0]\n",
    "embedding_dog=model.embeddings.word_embeddings(torch.tensor([tocken_dog_id]))\n",
    "\n",
    "tocken_wolf_id=tokenizer.convert_tokens_to_ids([\"wolf\"])[0]\n",
    "embedding_wolf=model.embeddings.word_embeddings(torch.tensor([tocken_wolf_id]))\n",
    "\n",
    "tocken_fish_id=tokenizer.convert_tokens_to_ids([\"fish\"])[0]\n",
    "embedding_fish=model.embeddings.word_embeddings(torch.tensor([tocken_fish_id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "712373ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3983], grad_fn=<SumBackward1>)\n",
      "tensor([0.3537], grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "cos=torch.nn.CosineSimilarity(dim=1,eps=1e-6)\n",
    "dog_wolf_similarity=cos(embedding_wolf,embedding_dog)\n",
    "print(dog_wolf_similarity)\n",
    "\n",
    "dog_fish_similarity=cos(embedding_fish,embedding_dog)\n",
    "print(dog_fish_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260c98e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
